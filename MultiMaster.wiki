#summary Multi Master Gerrit

We spent some time at the May 2012 Hackathon outlining an incremental approach to making open source Gerrit clusterable (the version running for android-review and gerrit-review is already clustered but uses much of Google's proprietary technologies such as GFS and !BigTable).  Several incremental steps were outlined 
on how to move Gerrit in that direction.  

= Shared Git Repo - Shared DB =

This is the simplest case for Gerrit multi master, so it is likely the first step 
which is needed by most other ideas is to support a very simple master/master installation of Gerrit where both (or all if more than 2) masters share a common filesystem backend (likely a high end NFS server) and a common db.

Two issues were identified here which need to be resolved 
before this is possible:  

  # Cache coherency and 
  # Submit conflict resolution
  # Mirror/Slave Replication

A naive approach to #1 is to simply use really short cache times, but this sort of defeats the purpose of caching.  To solve this properly, some sort of eviction protocol will need to be developed for masters to inform their peers of a needed eviction.  

#2 could be easily solved by manually determining a submit master and later 
upgrading to some sort of voting mechanism among peer masters to choose a submit master, these would be incremental approaches.  

A simple ssh connection between peers was deemed sufficient in most cases to accomplish both #1 and #2.


= Multi Site Masters with Separate Backends =

The main additional problem with separate backends is: resolving ref updates in a globally safe way.  In Googleâ€™s implementation, this is solved by placing the refs in !BigTable.  !ZooKeeper seemed like a good free/open source alternative since it is Java based and under the Apache license.  The other piece to solve is moving object data across sites, it was suggested that !ZooKeeper would likely be involved in helping to coordinate this, but details were not really discussed. 

= Distributed FS =

Finally, it was felt that once multi sites were conquered, that a distributed filesystem may eventually be needed to scale the git repos effectively, Hadoop DFS was proposed for this.